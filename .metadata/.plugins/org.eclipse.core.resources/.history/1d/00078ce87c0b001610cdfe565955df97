package com.buaa.hadoop1.contactor;

import java.io.IOException;
import java.io.InputStream;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;

public class ExcelIputFormat extends FileInputFormat<LongWritable, Text> {

	//这里默认的是系统实现的RecordReader，按行读取。我们要自定义这个类
	@Override
	public RecordReader<LongWritable, Text> createRecordReader(InputSplit split, TaskAttemptContext context)
			throws IOException, InterruptedException {
		
		return new ExcelRecordReader();
	}
	/******************************
	 * The record reader breaks the data into key/value pairs for input to the Mapper
	 * record用来拆分数据
	 * key:?????????????????????????????????????????????????????????????????????????????
	 * value:
	 */
	public class ExcelRecordReader extends RecordReader<LongWritable, Text>{
		private LongWritable key;
		private Text value;
		private InputStream is;

		@Override
		public void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException {
		}

		@Override
		public boolean nextKeyValue() throws IOException, InterruptedException {
			
			return false;
		}

		@Override
		public LongWritable getCurrentKey() throws IOException, InterruptedException {
			
			return null;
		}

		@Override
		public Text getCurrentValue() throws IOException, InterruptedException {
			
			return null;
		}

		@Override
		public float getProgress() throws IOException, InterruptedException {
			
			return 0;
		}

		@Override
		public void close() throws IOException {
		}
		
	}

}
